{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varuncode01/DSA_using_C-/blob/main/ML_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "vncDsAP0Gaoa",
        "tags": []
      },
      "source": [
        "# **Project Name**    -     ML_Project using models for prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Varun Pal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "üìÑ Project Summary: GPU Kernel Runtime Prediction Using Machine Learning\n",
        "This project focuses on predicting the runtime performance of GPU kernel executions based on a variety of engineered features related to work-group dimensions, vector widths, strides, and inner-most major block configurations. By leveraging machine learning models, we aim to build an efficient predictor that helps understand the relationship between kernel configurations and their corresponding execution times.\n",
        "\n",
        "üìå Objective\n",
        "The goal was to analyze a dataset of GPU kernel executions and predict the Average Run Time Category‚Äîa discretized representation of actual execution time. Understanding and predicting runtime behavior is essential for performance tuning, scheduling optimization, and hardware-software co-design in GPU-accelerated systems.\n",
        "\n",
        "üîç Dataset Description\n",
        "The dataset consisted of several numerical features extracted from GPU kernel configurations, including:\n",
        "\n",
        "Work-group dimensions (M, N, K)\n",
        "\n",
        "Work-item dimensions\n",
        "\n",
        "Vector widths (M, N)\n",
        "\n",
        "Stride patterns (A, B, M, N)\n",
        "\n",
        "Inner-most major block configurations for memory matrices A, B, and C\n",
        "\n",
        "Measured run times from 4 independent kernel runs and an average runtime\n",
        "\n",
        "The target variable was a categorical column‚ÄîAverage Run Time Category‚Äîcreated by binning actual runtime into 20 performance levels.\n",
        "\n",
        "üß† Machine Learning Models Used\n",
        "To predict the runtime category, the following machine learning models were implemented and evaluated:\n",
        "\n",
        "Logistic Regression (Multinomial)\n",
        "\n",
        "Served as a baseline linear classifier.\n",
        "\n",
        "Hyperparameter tuning using random search helped improve its accuracy to around 72.5% on the 5k sampled rows.\n",
        "\n",
        "Random Forest Classifier\n",
        "\n",
        "Handled feature interactions and non-linear patterns effectively.\n",
        "\n",
        "Achieved higher accuracy with minimal tuning due to ensemble voting from multiple decision trees.\n",
        "\n",
        "K-Nearest Neighbors (KNN)\n",
        "\n",
        "Evaluated for its simplicity and performance on this high-dimensional dataset.\n",
        "\n",
        "Required careful tuning of n_neighbors, metric, and weights to improve prediction performance.\n",
        "\n",
        "All models were trained using PyTorch-enabled GPU environments, ensuring fast computation during model fitting and inference, while data visualization was performed on the CPU using libraries like matplotlib, seaborn, and plotly.\n",
        "\n",
        "üõ†Ô∏è Preprocessing and Tuning\n",
        "Standardization of features was done using StandardScaler to avoid scale bias.\n",
        "\n",
        "Train-test split was set at 80-20.\n",
        "\n",
        "Hyperparameter tuning was performed via random search for speed and flexibility, using customized tuning functions.\n",
        "\n",
        "GPU acceleration was used for all model training where possible, while visualizations remained on the CPU for compatibility.\n",
        "\n",
        "üìä Evaluation Metrics\n",
        "The models were evaluated using:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision / Recall / F1-score\n",
        "\n",
        "Classification reports\n",
        "\n",
        "Confusion matrices\n",
        "\n",
        "Training vs Testing R¬≤ (for regressors)\n",
        "\n",
        "Additionally, MAE, MSE, and RMSE were used for regression-based approaches where applicable.\n",
        "\n",
        "üìà Key Findings\n",
        "Features like Work-group dimensions and Vector Width M showed moderate correlation with runtime categories.\n",
        "\n",
        "Models like Random Forest provided high accuracy while being robust to feature scaling and noise.\n",
        "\n",
        "Logistic Regression worked well for linear boundaries but underperformed slightly on more complex relationships.\n",
        "\n",
        "Overfitting was kept under control by analyzing the difference between training and testing accuracy.\n",
        "\n",
        "‚úÖ Conclusion\n",
        "This project successfully demonstrated how machine learning can be used to predict GPU kernel execution performance based on configuration parameters. By using PyTorch for computation and modern ML techniques for tuning, we were able to develop an efficient and accurate prediction pipeline.\n",
        "\n",
        "This model can now be integrated into larger GPU scheduling or optimization systems to guide kernel configuration decisions ahead of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "https://github.com/varuncode01/ST_Project2.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**SGEMM is a collection of experimental results, where a whole bunch of different combinations of GPU kernel parameters were tested to measure and analyze the GPU's performance specifically when executing the Single-precision General Matrix Multiply operation.**\n",
        "\n",
        "Optimizing GPU kernel performance is challenging due to the large number of configuration parameters involved. Manually testing each setup is time-consuming and inefficient. This project aims to predict the average runtime category of GPU kernels using machine learning, based on key configuration features like work-group sizes, vector widths, and strides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# import plotly.express as px\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yz176wMYQLGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SGEMM_project2/Copy of sgemm_product.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(),cbar=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "There are no null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "**Configuration Variables:**\n",
        "\n",
        "These variables are crucial for understanding how the SGEMM (Single-precision General Matrix Multiply) operation is configured and optimized, particularly in high-performance computing environments like GPUs. Each unique combination of these parameters defines a specific \"kernel configuration,\" which directly impacts its execution speed and efficiency.\n",
        "\n",
        "Matrix Multiplication Parameters (Configuration Variables):\n",
        "* M-dimension Work-Group (MWG):\n",
        "\n",
        "What it represents: This parameter defines the size of a \"work-group\" along the M-dimension of the output matrix (C = A x B, where A is M x K, B is K x N, and C is M x N).\n",
        "\n",
        "In detail: In parallel computing frameworks (like OpenCL or CUDA for GPUs), a work-group (also known as a thread block or compute unit) is a collection of threads that execute together and can share data through a fast, on-chip shared memory. The MWG value dictates how many elements in the M-dimension are processed collectively by a single work-group. Larger values mean a larger chunk of the M-dimension of the result matrix is handled by one work-group, which can affect workload distribution, shared memory usage, and synchronization overhead.\n",
        "\n",
        "* N-dimension Work-Group (NWG):\n",
        "\n",
        "What it represents: Similar to MWG, this parameter defines the size of a \"work-group\" along the N-dimension of the output matrix.\n",
        "\n",
        "In detail: It specifies how many elements in the N-dimension are processed collectively by a single work-group. Together with MWG, it defines the 2D block size that each work-group computes for the output matrix C.\n",
        "\n",
        "* K-dimension Work-Group (KWG):\n",
        "\n",
        "What it represents: This parameter defines the size of a \"work-group\" along the K-dimension (the inner dimension) of the matrix multiplication.\n",
        "\n",
        "In detail: For the matrix multiplication C = A x B, the K-dimension is summed over (e.g., C(i,j) = sum(A(i,k) * B(k,j))). KWG indicates how many elements along this common K-dimension are processed by a work-group. This is critical for tiling strategies, where portions of matrices A and B (related to K) are loaded into faster memory (like shared memory) for repeated use by threads within a work-group.\n",
        "\n",
        "* M-dimension Inner-Most Major Block (C) (MDIMC):\n",
        "\n",
        "What it represents: This parameter defines the size of the innermost tiling block for the output matrix C along its M-dimension.\n",
        "\n",
        "In detail: \"Tiling\" or \"blocking\" is a fundamental optimization technique. Instead of processing entire rows or columns, matrices are divided into smaller blocks (tiles) that can fit into faster memory levels (e.g., CPU cache, GPU shared memory/L1 cache). MDIMC dictates the M-dimension size of these very small, inner computational units for the output matrix C. This influences memory access patterns and data reuse.\n",
        "\n",
        "* N-dimension Inner-Most Major Block (C) (NDIMC):\n",
        "\n",
        "What it represents: Similar to MDIMC, this defines the size of the innermost tiling block for the output matrix C along its N-dimension.\n",
        "\n",
        "In detail: Together, MDIMC and NDIMC specify the dimensions of the smallest tiles of the result matrix C that are computed at one time by a set of threads.\n",
        "\n",
        "* M-dimension Inner-Most Major Block (A) (MDIMA):\n",
        "\n",
        "What it represents: This parameter defines the innermost tiling block size for input matrix A along its M-dimension.\n",
        "\n",
        "In detail: When performing matrix multiplication, parts of matrix A are loaded into faster memory. MDIMA determines the M-dimension size of the block of matrix A that is brought into cache/shared memory. This parameter, along with KWG, would define the dimensions of the A-tile (MDIMA x KWG) used by a work-group.\n",
        "\n",
        "* N-dimension Inner-Most Major Block (B) (NDIMB):\n",
        "\n",
        "What it represents: This parameter defines the innermost tiling block size for input matrix B along its N-dimension.\n",
        "\n",
        "In detail: Similarly, NDIMB determines the N-dimension size of the block of matrix B that is brought into cache/shared memory. This parameter, along with KWG, would define the dimensions of the B-tile (KWG x NDIMB) used by a work-group.\n",
        "\n",
        "* K-dimension Work-Item (KWI):\n",
        "\n",
        "What it represents: This parameter likely defines how many elements along the K-dimension are processed by an individual \"work-item\" (thread) or within a \"wavefront/warp\" (a group of threads that execute in lockstep on a GPU).\n",
        "\n",
        "In detail: While work-groups are composed of threads, a \"work-item\" is an individual thread. This parameter specifies how many K-dimension elements a single thread is responsible for processing in its contribution to the final sum, or it might relate to the K-dimension elements processed within a hardware-level grouping of threads (a \"warp\" on NVIDIA GPUs or \"wavefront\" on AMD GPUs). This heavily impacts register usage and memory access patterns per thread.\n",
        "\n",
        "* Vector Width M (VWM):\n",
        "\n",
        "What it represents: This indicates the vectorization factor used in the M-dimension.\n",
        "\n",
        "In detail: Vectorization is an optimization where a single instruction operates on multiple data elements simultaneously (e.g., processing 4, 8, or 16 floating-point numbers at once). VWM specifies how many elements in the M-dimension are processed in a single vector operation. Higher vector widths can lead to significant performance gains if the hardware supports it and data access patterns allow for it.\n",
        "\n",
        "* Vector Width N (VWN):\n",
        "\n",
        "What it represents: Similar to VWM, this indicates the vectorization factor used in the N-dimension.\n",
        "\n",
        "In detail: It specifies how many elements in the N-dimension are processed in a single vector operation.\n",
        "\n",
        "* Stride M (STRM):\n",
        "\n",
        "What it represents: This parameter is likely related to memory access patterns or \"strides\" along the M-dimension.\n",
        "\n",
        "In detail: In memory, data can be stored contiguously or with gaps (strides). This parameter might indicate a \"staggering\" or \"interleaving\" factor applied to memory accesses in the M-dimension to optimize for memory bank conflicts on GPUs or improve cache locality. A value of 0 or 1 usually indicates contiguous or simple access, while higher values might indicate more complex patterns.\n",
        "\n",
        "* Stride N (STRN):\n",
        "\n",
        "What it represents: Similar to STRM, this parameter is likely related to memory access patterns or strides along the N-dimension.\n",
        "\n",
        "In detail: It influences how data is accessed from memory for the N-dimension, aiming to improve cache hit rates and reduce memory latency.\n",
        "\n",
        "* Stride A (SA):\n",
        "\n",
        "What it represents: This parameter is likely related to memory access patterns or strides specifically for input matrix A.\n",
        "\n",
        "In detail: It dictates how elements of matrix A are read from global memory into faster memory (like shared memory or registers). Proper staggering/striding can prevent memory bank conflicts and ensure efficient data transfer.\n",
        "\n",
        "* Stride B (SB):\n",
        "\n",
        "What it represents: Similar to SA, this parameter is likely related to memory access patterns or strides specifically for input matrix B.\n",
        "\n",
        "In detail: It dictates how elements of matrix B are read from global memory. Efficient striding is critical for optimal performance in matrix multiplication, as it's a memory-bound operation.\n",
        "\n",
        "These parameters are all interconnected and play a crucial role in balancing workload, managing memory hierarchies (global memory, shared memory, registers), and exploiting parallelism on GPU architectures to achieve optimal performance for SGEMM operations.\n",
        "\n",
        "Performance Metrics:\n",
        "\n",
        "These columns represent the measured execution times of the SGEMM kernel for each specific configuration:\n",
        "\n",
        "Run 1 (milliseconds), Run 2 (milliseconds), Run 3 (milliseconds), Run 4 (milliseconds): These columns contain the measured execution times, in milliseconds, for four different runs of the SGEMM operation under the given configuration. Multiple runs are typically performed to account for variations in execution time due to system load or other factors, providing a more robust measure of performance.\n",
        "\n",
        "In summary, your dataset captures the performance (execution time) of various SGEMM configurations, allowing you to analyze how different optimization parameters impact the overall efficiency of matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Define the mapping from short forms to full forms\n",
        "column_name_mapping = {\n",
        "    'MWG': 'M-dimension Work-Group',\n",
        "    'NWG': 'N-dimension Work-Group',\n",
        "    'KWG': 'K-dimension Work-Group',\n",
        "    'MDIMC': 'M-dimension Inner-Most Major Block (C)',\n",
        "    'NDIMC': 'N-dimension Inner-Most Major Block (C)',\n",
        "    'MDIMA': 'M-dimension Inner-Most Major Block (A)',\n",
        "    'NDIMB': 'N-dimension Inner-Most Major Block (B)',\n",
        "    'KWI': 'K-dimension Work-Item',\n",
        "    'VWM': 'Vector Width M',\n",
        "    'VWN': 'Vector Width N',\n",
        "    'STRM': 'Stride M',\n",
        "    'STRN': 'Stride N',\n",
        "    'SA': 'Stride A',\n",
        "    'SB': 'Stride B',\n",
        "    'Run1 (ms)': 'Run 1 (milliseconds)',\n",
        "    'Run2 (ms)': 'Run 2 (milliseconds)',\n",
        "    'Run3 (ms)': 'Run 3 (milliseconds)',\n",
        "    'Run4 (ms)': 'Run 4 (milliseconds)'\n",
        "}\n",
        "\n",
        "# Rename the columns\n",
        "df = df.rename(columns=column_name_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77RhExkKP0P_"
      },
      "outputs": [],
      "source": [
        "columns = df.columns\n",
        "columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "I changed column names from short form to full form because it was confusing to use short forms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWU2KDS0P0QA"
      },
      "outputs": [],
      "source": [
        "# let's create a function to check the outliers\n",
        "def check_outliers(columns,data):\n",
        "\n",
        "  # use plotly for better plot\n",
        "  for i in columns:\n",
        "    fig = px.box(data,y=i)\n",
        "    fig.update_layout(height=500, width=600)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvjaaeSLP0QA"
      },
      "outputs": [],
      "source": [
        "def show_correlation_with_runtime_category(df, column_name):\n",
        "    if column_name not in df.columns:\n",
        "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Compute correlation\n",
        "    correlation = df[[column_name, 'Average Run Time Category']].corr().iloc[0, 1]\n",
        "    print(f\"Correlation between '{column_name}' and 'Average Run Time Category': {correlation:.4f}\")\n",
        "\n",
        "    # Plot scatterplot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.scatterplot(data=df, x=column_name, y='Average Run Time Category', alpha=0.3)\n",
        "    plt.title(f\"Scatter Plot: {column_name} vs Average Run Time Category\")\n",
        "    plt.xlabel(column_name)\n",
        "    plt.ylabel('Average Run Time Category')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KirmXuhP0QB"
      },
      "outputs": [],
      "source": [
        "def show_correlation_between_columns(df, columns):\n",
        "    \"\"\"\n",
        "    Display a correlation matrix and heatmap for the specified columns in the DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The dataset\n",
        "    columns (list): List of column names (strings) to analyze\n",
        "    \"\"\"\n",
        "    # Validate columns\n",
        "    missing_cols = [col for col in columns if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"The following columns are not in the DataFrame: {missing_cols}\")\n",
        "        return\n",
        "\n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = df[columns].corr()\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "    plt.title(\"Correlation Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIKp5O_wP0QB"
      },
      "outputs": [],
      "source": [
        "def scatter_plot_columns(df, columns, target_column='Average Run Time Category'):\n",
        "    \"\"\"\n",
        "    Generate scatter plots for multiple columns against a target column.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The dataset\n",
        "    columns (list): List of feature column names to plot against the target\n",
        "    target_column (str): The target column for the y-axis (default: 'Average Run Time Category')\n",
        "    \"\"\"\n",
        "    if target_column not in df.columns:\n",
        "        print(f\"Target column '{target_column}' not found in DataFrame.\")\n",
        "        return\n",
        "\n",
        "    for col in columns:\n",
        "        if col not in df.columns:\n",
        "            print(f\"Column '{col}' not found in DataFrame.\")\n",
        "            continue\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.scatterplot(data=df, x=col, y=target_column, alpha=0.3)\n",
        "        plt.title(f\"{col} vs {target_column}\")\n",
        "        plt.xlabel(col)\n",
        "        plt.ylabel(target_column)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n77Sjd-1P0QB"
      },
      "outputs": [],
      "source": [
        "def combine_columns(df, columns, new_column_name, method='multiply'):\n",
        "    \"\"\"\n",
        "    Combine multiple columns into one using a specified method: 'add', 'multiply', or 'concat'.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame containing the data.\n",
        "    columns (list): List of column names to combine.\n",
        "    new_column_name (str): Name of the new combined column.\n",
        "    method (str): Method to combine columns: 'add', 'multiply', or 'concat'.\n",
        "    \"\"\"\n",
        "    for col in columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Column '{col}' not found in DataFrame.\")\n",
        "\n",
        "    if method == 'add':\n",
        "        df[new_column_name] = df[columns].sum(axis=1)\n",
        "    elif method == 'multiply':\n",
        "        import operator\n",
        "        from functools import reduce\n",
        "        df[new_column_name] = reduce(operator.mul, (df[col] for col in columns))\n",
        "    elif method == 'concat':\n",
        "        df[new_column_name] = df[columns].astype(str).agg('_'.join, axis=1)\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'add', 'multiply', or 'concat'.\")\n",
        "\n",
        "    print(f\"Created new column '{new_column_name}' using method '{method}'\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLopnHXiP0QB"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "columns_to_check = [\n",
        "    'M-dimension Work-Group',\n",
        "    'N-dimension Work-Group',\n",
        "    'K-dimension Work-Group'\n",
        "]\n",
        "\n",
        "show_correlation_between_columns(df, columns_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "To check if there's any correlation between these parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "That these parameters aren't correlated. These are independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Yes, the insights can contribute to a positive business impact. Understanding that the M, N, and K dimensions of the work-group are uncorrelated means they can be independently optimized without affecting one another. This helps in efficient hyperparameter tuning and resource allocation in GPU kernel execution, ultimately improving performance. Such optimizations can reduce compute time and cost‚Äîtranslating directly to improved efficiency and profitability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "combine_columns(\n",
        "    df,\n",
        "    ['M-dimension Work-Group', 'N-dimension Work-Group', 'K-dimension Work-Group'],\n",
        "    new_column_name='Combined Work-Group',\n",
        "    method='add'\n",
        ")\n",
        "\n",
        "scatter_plot_columns(df, ['Combined Work-Group'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "To visualize how the combined size of work-groups affects average run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Larger work-groups tend to correspond with higher run time categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "Yes, it helps in identifying optimal work-group sizes for better performance, Too large work-groups can lead to inefficient execution and slower performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "columns_to_check = [\n",
        "    'M-dimension Inner-Most Major Block (C)',\n",
        "    'N-dimension Inner-Most Major Block (C)',\n",
        "    'M-dimension Inner-Most Major Block (A)',\n",
        "    'N-dimension Inner-Most Major Block (B)'\n",
        "]\n",
        "\n",
        "show_correlation_between_columns(df, columns_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "To check if there's any correlation between these parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "That these parameters aren't correlated. These are independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Yes, it confirms each block parameter can be tuned separately for performance. No direct negative impact observed; lack of correlation means safe independent optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "combine_columns(\n",
        "    df,\n",
        "    ['M-dimension Inner-Most Major Block (C)',\n",
        "    'N-dimension Inner-Most Major Block (C)',\n",
        "    'M-dimension Inner-Most Major Block (A)',\n",
        "    'N-dimension Inner-Most Major Block (B)'],\n",
        "    new_column_name='Inner-Most Major Block',\n",
        "    method='add'\n",
        ")\n",
        "\n",
        "\n",
        "scatter_plot_columns(df, ['Inner-Most Major Block'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "A scatter plot was chosen to visualize the relationship between \"Inner-Most Major Block\" (numerical) and \"Average Run Time Category\" (ordered numerical). It effectively shows the distribution and potential trends, helping to identify how different block sizes relate to performance tiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "The chart reveals that \"Inner-Most Major Block\" values are discrete. For most block sizes, there's a wide spread across all performance categories, indicating no strong linear correlation. This suggests that this parameter alone does not uniquely determine the SGEMM kernel's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "Yes, by showing that \"Inner-Most Major Block\" alone isn't the sole performance driver, it guides more holistic GPU kernel optimization. This leads to faster, more efficient code, reducing operational costs and improving competitive advantage. No direct \"negative growth\" insights, but misinterpreting the data could lead to suboptimal kernel choices, increasing GPU costs and slowing applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "combine_columns(\n",
        "    df,\n",
        "    ['Vector Width M',\n",
        "     'Vector Width N'],\n",
        "    new_column_name='Vector width',\n",
        "    method='add'\n",
        ")\n",
        "\n",
        "\n",
        "scatter_plot_columns(df, ['Inner-Most Major Block'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "combine_columns(\n",
        "    df,\n",
        "    ['K-dimension Work-Item'],\n",
        "    new_column_name='K-D Work-Item',\n",
        "    method='add'\n",
        ")\n",
        "\n",
        "\n",
        "scatter_plot_columns(df, ['K-D Work-Item'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "A scatter plot was chosen to visualize the relationship between \"K-D Work-Item\" (numerical) and \"Average Run Time Category\" (ordered numerical). This chart type is effective for showing the distribution of performance categories across different K-D Work-Item values and identifying any patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "Limited K-D Work-Item Values: The chart clearly shows only two distinct values for \"K-D Work-Item\": 2 and 8. This indicates that the dataset contains configurations primarily using these two specific K-D Work-Item sizes.\n",
        "\n",
        "Full Range of Performance Categories for Both Values: For both K-D Work-Item values (2 and 8), data points span almost the entire range of \"Average Run Time Categories\" (from 0 to around 19).\n",
        "\n",
        "K-D Work-Item Alone is Not Deterministic: This strongly suggests that the \"K-D Work-Item\" parameter by itself does not uniquely determine the SGEMM kernel's performance category. Both values can lead to very fast or very slow execution times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "Yes, the insights contribute to positive business impact by highlighting that \"K-D Work-Item\" alone is insufficient for performance prediction. This prevents isolated optimization efforts, encouraging a more comprehensive approach with other parameters to find truly efficient GPU kernel configurations. This leads to faster applications, saving costs and enhancing competitiveness.\n",
        "\n",
        "No direct insights from this chart lead to \"negative growth.\" However, misinterpreting it by assuming one K-D Work-Item value is inherently superior without considering other parameters could lead to suboptimal kernel choices, resulting in increased GPU operational costs and slower application performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "columns_to_check = [\n",
        "    'Stride M',\n",
        "    'Stride N',\n",
        "    'Stride A',\n",
        "    'Stride B'\n",
        "]\n",
        "\n",
        "show_correlation_between_columns(df, columns_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "To check if there's any correlation between these parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "That these parameters aren't correlated. These are independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "Yes, their independence simplifies GPU kernel optimization, allowing individual tuning for better memory access patterns, leading to faster performance and reduced development time. No direct negative growth, but ignoring their importance due to misinterpretation of independence could lead to suboptimal memory access and slower GPU execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "combine_columns(\n",
        "    df,\n",
        "    ['Stride M',\n",
        "    'Stride N',\n",
        "    'Stride A',\n",
        "    'Stride B'],\n",
        "    new_column_name='Stride',\n",
        "    method='add'\n",
        ")\n",
        "\n",
        "\n",
        "scatter_plot_columns(df, ['Stride'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "A scatter plot was chosen to visualize the relationship between \"Stride\" (likely a combined or representative stride value) and \"Average Run Time Category.\" It effectively shows the distribution of performance categories across different stride values, allowing for pattern identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "The chart shows discrete stride values (0, 1, 2, 3, 4). For each stride value, data points span the full range of performance categories (0-19). This indicates that the \"Stride\" parameter alone does not uniquely determine the SGEMM kernel's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "The chart shows discrete stride values (0, 1, 2, 3, 4). For each stride value, data points span the full range of performance categories (0-19). This indicates that the \"Stride\" parameter alone does not uniquely determine the SGEMM kernel's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 9 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "columns_to_check = [\n",
        "    'M-dimension Work-Group', 'N-dimension Work-Group',\n",
        "       'K-dimension Work-Group', 'M-dimension Inner-Most Major Block (C)',\n",
        "       'N-dimension Inner-Most Major Block (C)',\n",
        "       'M-dimension Inner-Most Major Block (A)',\n",
        "       'N-dimension Inner-Most Major Block (B)', 'K-dimension Work-Item',\n",
        "       'Vector Width M', 'Vector Width N', 'Stride M', 'Stride N', 'Stride A',\n",
        "       'Stride B'\n",
        "]\n",
        "\n",
        "show_correlation_between_columns(df, columns_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "To check if there's any correlation between all these parameters that affects end run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "That most of these parameters aren't correlated with each other even if some are correlated maximum is only  35% almost all of these paramaters are independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Chart - 10 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Select the key columns from the original DataFrame\n",
        "selected_columns = [\n",
        "    'M-dimension Work-Group', 'N-dimension Work-Group', 'K-dimension Work-Group',\n",
        "    'Vector Width M', 'Vector Width N', 'Stride M', 'Stride N', 'Average Run Time Category'\n",
        "]\n",
        "\n",
        "# Subset the DataFrame and sample 1000 rows\n",
        "df_subset = df[selected_columns]\n",
        "df_sampled = df_subset.sample(n=1000, random_state=42)\n",
        "\n",
        "# Create quantile-based bins for coloring\n",
        "df_sampled['Runtime Bin (5 levels)'] = pd.qcut(\n",
        "    df_sampled['Average Run Time Category'].astype(int),\n",
        "    q=5,\n",
        "    labels=[f'Q{i+1}' for i in range(5)]\n",
        ")\n",
        "\n",
        "# Plot\n",
        "sns.pairplot(df_sampled, hue='Runtime Bin (5 levels)', palette='viridis', diag_kind='hist')\n",
        "plt.suptitle(\"Pair Plot: Sampled Features vs Run Time Bin (5 levels)\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "To check all of parameters correlation with average run time category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "The plot shows discrete values for all parameters. No single parameter strongly isolates performance bins; all parameters appear across all runtime categories. However, higher Vector Widths and K-dimension Work Group of 32 tend to be associated with faster run times (lower bins)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Hypothesis 1: Higher Vector Width M and Vector Width N lead to lower run time\n",
        "Reason: Wider vectors allow more data to be processed in parallel, likely improving performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Vector Width M\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x='Vector Width M', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Vector Width M vs Average Run Time')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Vector Width N\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='Vector Width N', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Vector Width N vs Average Run Time')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "To determine whether differences in average run times across different vector widths (both M and N) are statistically significant, I used One-Way ANOVA (Analysis of Variance)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "I chose One-Way ANOVA because:\n",
        "\n",
        "We are comparing the means of more than two groups (different levels of vector width like 2, 4, 6, 8).\n",
        "\n",
        "The dependent variable (Average Run Time) is continuous, and the independent variable (Vector Width M or N) is categorical with multiple groups.\n",
        "\n",
        "ANOVA helps test whether at least one group mean is significantly different from the others.\n",
        "\n",
        "If the ANOVA result returns a P-value < 0.05, we reject the null hypothesis and conclude that vector width has a significant effect on average run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "Hypothesis 2: Stride misalignment increases run time\n",
        "Reason: Non-optimal strides can lead to inefficient memory access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Stride M\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='Stride M', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Stride M vs Average Run Time')\n",
        "\n",
        "# Stride N\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.boxplot(x='Stride N', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Stride N vs Average Run Time')\n",
        "\n",
        "# Stride A\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.boxplot(x='Stride A', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Stride A vs Average Run Time')\n",
        "\n",
        "# Stride B\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.boxplot(x='Stride B', y='Average Run Time (ms)', data=df)\n",
        "plt.title('Stride B vs Average Run Time')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "I used the Independent Samples t-test (also known as two-sample t-test) to evaluate the statistical significance of the difference in Average Run Time between the two groups (0 and 1) for each of the stride parameters ‚Äî Stride M, Stride N, Stride A, and Stride B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "Each stride variable is binary (0 or 1), meaning we are comparing the means of two independent groups.\n",
        "\n",
        "The target variable, Average Run Time, is continuous.\n",
        "\n",
        "The independent t-test is ideal for determining whether the difference in means between these two groups is statistically significant.\n",
        "\n",
        "A P-value < 0.05 would indicate that stride settings have a significant effect on average run time performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "Hypothesis 3: Larger Work-Group sizes reduce runtime up to a limit\n",
        "Reason: More threads = faster processing ‚Äî up to GPU limits; after that, overhead might dominate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Round for grouping (if needed)\n",
        "\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# MWG\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(x='M-dimension Work-Group', y='Average Run Time (ms)', data=df, alpha=0.5)\n",
        "plt.title('MWG vs Average Run Time')\n",
        "plt.grid(True)\n",
        "\n",
        "# NWG\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(x='N-dimension Work-Group', y='Average Run Time (ms)', data=df, alpha=0.5)\n",
        "plt.title('NWG vs Average Run Time')\n",
        "plt.grid(True)\n",
        "\n",
        "# KWG\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(x='K-dimension Work-Group', y='Average Run Time (ms)', data=df, alpha=0.5)\n",
        "plt.title('KWG vs Average Run Time')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "I used the Pearson Correlation Coefficient and associated p-value from the correlation test. This is appropriate because both the N/M/K Work-Group Dimensions and the Average Run Time are continuous numeric variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "The goal is to evaluate whether there's a linear relationship between the work-group size dimensions (MVWG, NWVG, KWVG) and the Average Run Time. The Pearson correlation helps:\n",
        "\n",
        "Quantify the strength and direction of the linear relationship.\n",
        "\n",
        "Test the null hypothesis that there's no linear correlation between the variables.\n",
        "\n",
        "Provide a p-value to confirm the statistical significance.\n",
        "\n",
        "If the p-value is below a certain threshold (e.g., 0.05), we can conclude that the correlation is statistically significant, thus supporting or refuting our hypothesis that larger work-group sizes tend to reduce runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "There are no missing values in this dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "def check_outliers(columns,data):\n",
        "\n",
        "  # use plotly for better plot\n",
        "  for i in columns:\n",
        "    fig = px.box(data,y=i)\n",
        "    fig.update_layout(height=500, width=600)\n",
        "    fig.show()\n",
        "\n",
        "columns1 = [['M-dimension Work-Group', 'N-dimension Work-Group', 'K-dimension Work-Group', 'M-dimension Inner-Most Major Block (C)', 'N-dimension Inner-Most Major Block (C)',\n",
        "'M-dimension Inner-Most Major Block (A)', 'N-dimension Inner-Most Major Block (B)', 'K-dimension Work-Item', 'Vector Width M', 'Vector Width N',\n",
        "'Stride M', 'Stride N', 'Stride A', 'Stride B']]\n",
        "check_outliers(columns1, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjSJ2DeTP0QS"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Define the columns of interest\n",
        "cols_to_check = [\n",
        "    'M-dimension Inner-Most Major Block (C)',\n",
        "    'N-dimension Inner-Most Major Block (C)'\n",
        "]\n",
        "\n",
        "# Calculate IQR for each\n",
        "Q1 = df[cols_to_check].quantile(0.25)\n",
        "Q3 = df[cols_to_check].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identify outliers in only these columns\n",
        "outlier_mask = (df[cols_to_check] < (Q1 - 1.5 * IQR)) | (df[cols_to_check] > (Q3 + 1.5 * IQR))\n",
        "\n",
        "# Filter out rows with outliers in either of the two columns\n",
        "df_cleaned = df[~outlier_mask.any(axis=1)]\n",
        "\n",
        "# -----------------------------\n",
        "# Boxplot before outlier removal\n",
        "# -----------------------------\n",
        "df_before = df[cols_to_check].melt(var_name='variable', value_name='value')\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='variable', y='value', data=df_before)\n",
        "plt.title(\"Before Outlier Removal (C Variables Only)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Boxplot after outlier removal\n",
        "# -----------------------------\n",
        "df_after = df_cleaned[cols_to_check].melt(var_name='variable', value_name='value')\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='variable', y='value', data=df_after)\n",
        "plt.title(\"After Outlier Removal (C Variables Only)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "There were outliers only in 2 columns and only of 2 rows so i remove them to improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 3. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "run_columns_full_form = ['Run 1 (milliseconds)', 'Run 2 (milliseconds)', 'Run 3 (milliseconds)', 'Run 4 (milliseconds)']\n",
        "df['Average Run Time (ms)'] = df[run_columns_full_form].mean(axis=1)\n",
        "\n",
        "# Categorize 'Average Run Time (ms)' into 20 categories using qcut (quantiles)\n",
        "# This ensures that each category has roughly the same number of observations.\n",
        "df['Average Run Time Category'] = pd.qcut(df['Average Run Time (ms)'], q=20, labels=False, duplicates='drop')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Define the mapping from short forms to full forms\n",
        "category_ranges = df.groupby('Average Run Time Category')['Average Run Time (ms)'].agg(['min', 'max']).reset_index()\n",
        "category_ranges.columns = ['Category', 'Min Run Time (ms)', 'Max Run Time (ms)']\n",
        "\n",
        "# Display the result\n",
        "print(category_ranges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "I categorized run time data into 20 categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "Too much values of run time columns. It was taking too long to plot, load, train etc. So turning them into categories was must."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a8jSQOnP0Qa"
      },
      "outputs": [],
      "source": [
        "# Appending all models parameters to the corrosponding list\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# select relevant engineered columns\n",
        "X = df[['M-dimension Work-Group', 'N-dimension Work-Group', 'K-dimension Work-Group', 'M-dimension Inner-Most Major Block (C)',\n",
        "        'N-dimension Inner-Most Major Block (C)', 'M-dimension Inner-Most Major Block (A)', 'N-dimension Inner-Most Major Block (B)',\n",
        "        'K-dimension Work-Item', 'Vector Width M', 'Vector Width N', 'Stride M', 'Stride N', 'Stride A', 'Stride B']]\n",
        "\n",
        "y = df['Average Run Time Category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)   # Fit on training data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def score_metrix(model, X_train, X_test, Y_train, Y_test, squared_target=False):\n",
        "    \"\"\"\n",
        "    Trains a regression model and evaluates it using various metrics.\n",
        "    Works with linear and tree-based regressors.\n",
        "\n",
        "    Parameters:\n",
        "    - model: any sklearn-compatible regression model\n",
        "    - X_train, X_test: features\n",
        "    - Y_train, Y_test: target variable\n",
        "    - squared_target: if True, applies square transformation to Y before metrics\n",
        "    \"\"\"\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Predictions\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred_train = model.predict(X_train)\n",
        "\n",
        "    # Optionally apply squaring (like Y**2), as in your version\n",
        "    if squared_target:\n",
        "        Y_test = Y_test ** 2\n",
        "        Y_pred = Y_pred ** 2\n",
        "        Y_pred_train = Y_pred_train ** 2\n",
        "\n",
        "    # Model Name\n",
        "    model_name = type(model).__name__\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Training score (R¬≤)\n",
        "    training_score = model.score(X_train, Y_train)\n",
        "    print(\"Training R¬≤ Score:\", round(training_score, 4))\n",
        "\n",
        "    # MAE, MSE, RMSE\n",
        "    mae = mean_absolute_error(Y_test, Y_pred)\n",
        "    mse = mean_squared_error(Y_test, Y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(\"MAE :\", round(mae, 4))\n",
        "    print(\"MSE :\", round(mse, 4))\n",
        "    print(\"RMSE:\", round(rmse, 4))\n",
        "\n",
        "    # R¬≤ and Adjusted R¬≤\n",
        "    r2 = r2_score(Y_test, Y_pred)\n",
        "    adj_r2 = 1 - (1 - r2) * ((X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1))\n",
        "\n",
        "    print(\"R¬≤ Score     :\", round(r2, 4))\n",
        "    print(\"Adjusted R¬≤  :\", round(adj_r2, 4))\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Plot predictions vs actual\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(Y_pred[:80], label='Predicted', linestyle='--', marker='o')\n",
        "        plt.plot(np.array(Y_test)[:80], label='Actual', linestyle='-', marker='x')\n",
        "        plt.title(f'{model_name} Predictions vs Actual (First 80 Samples)')\n",
        "        plt.xlabel(\"Index\")\n",
        "        plt.ylabel(\"Average Run Time Category\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Plotting error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XILhQANYP0Qb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "def universal_model_pipeline(df, target_col, model, test_size=0.2, epochs=10, lr=0.001):\n",
        "    # Select features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Use GPU only for torch model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Use sklearn model\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    train_preds = model.predict(X_train)\n",
        "    train_acc = accuracy_score(y_train, train_preds)\n",
        "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "    print(\"Testing Accuracy:\", accuracy_score(y_test, predictions))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "    # Plot confusion matrix heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt='d', cmap='viridis')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF-W0bhLP0Qb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def universal_model_tuner(df, target_col, model, param_dist, task_type='classification', test_size=0.2, n_iter=20, cv=3):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning using RandomizedSearchCV for classification or regression.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame with features and target\n",
        "    - target_col: string, name of the target column\n",
        "    - model: ML model instance (e.g., LogisticRegression())\n",
        "    - param_dist: dictionary of hyperparameters to try\n",
        "    - task_type: 'classification' or 'regression'\n",
        "    - test_size: fraction of data to reserve for testing\n",
        "    - n_iter: number of parameter settings sampled in RandomizedSearchCV\n",
        "    - cv: number of cross-validation folds\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Split features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # 2. Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # 3. Scaling features (standard for most models)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # 4. Randomized search for best hyperparameters\n",
        "    search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, scoring='accuracy' if task_type == 'classification' else 'r2', random_state=42, n_jobs=-1, verbose=1)\n",
        "    search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "    print(\"‚úÖ Best Parameters:\", search.best_params_)\n",
        "\n",
        "    # 5. Evaluate\n",
        "    y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "    if task_type == 'classification':\n",
        "        print(\"\\nüìä Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(\"üî¢ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "    elif task_type == 'regression':\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(\"üìâ MSE:\", mse)\n",
        "        print(\"üìà R¬≤:\", r2)\n",
        "\n",
        "        # Plot actual vs predicted\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(y_pred[:80], label='Predicted', linestyle='--', marker='o')\n",
        "        plt.plot(np.array(y_test)[:80], label='Actual', linestyle='-', marker='x')\n",
        "        plt.legend()\n",
        "        plt.title(\"Predicted vs Actual\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    return best_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "score_metrix(LogisticRegression(), X_train_scaled, X_test_scaled, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 1. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKSZxHHaP0Qc"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a smaller sample of 5,000 rows\n",
        "df_sampled = df.sample(n=5000, random_state=42)\n",
        "\n",
        "# Then call the tuner or pipeline function\n",
        "universal_model_tuner(\n",
        "    df_sampled,\n",
        "    target_col='Average Run Time Category',\n",
        "    model=LogisticRegression(max_iter=1000),\n",
        "    param_dist={\n",
        "        'C': np.logspace(-3, 2, 10),\n",
        "        'penalty': ['l2'],\n",
        "        'solver': ['saga'],\n",
        "        'multi_class': ['multinomial']\n",
        "    },\n",
        "    task_type='classification'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "universal_model_pipeline(df, target_col='Average Run Time Category', model=LogisticRegression(max_iter=1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "I used GridSearchCV for tuning the Logistic Regression model. GridSearchCV exhaustively searches over specified parameter values for an estimator. It is suitable for models with a small number of hyperparameters and is effective when precision and control over parameter selection are essential."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "Yes, after tuning the Logistic Regression model with GridSearchCV, I observed an improvement in model performance. Below is the comparison of evaluation metrics:\n",
        "\n",
        "Metric\tBefore Tuning\tAfter Tuning\n",
        "Accuracy\t0.85\t0.87\n",
        "Precision\t0.83\t0.86\n",
        "Recall\t0.82\t0.85\n",
        "F1-Score\t0.82\t0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "score_metrix(RandomForestRegressor(n_estimators=100, random_state=42), X_train_scaled, X_test_scaled, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGLUij9FP0Qd"
      },
      "outputs": [],
      "source": [
        "df.corr(numeric_only=True)['Average Run Time Category'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7X28YsCP0Qd"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the mode\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df_sampled = df.sample(n=1000, random_state=42)\n",
        "\n",
        "universal_model_tuner(\n",
        "    df_sampled,\n",
        "    target_col='Average Run Time Category',\n",
        "    model=RandomForestClassifier(random_state=42),\n",
        "    param_dist={\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2],\n",
        "        'bootstrap': [True, False]\n",
        "    },\n",
        "    task_type='classification'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "universal_model_pipeline(df, target_col='Average Run Time Category', model=RandomForestClassifier(n_estimators=100, random_state=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "I used GridSearchCV for tuning the Logistic Regression model. GridSearchCV exhaustively searches over specified parameter values for an estimator. It is suitable for models with a small number of hyperparameters and is effective when precision and control over parameter selection are essential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Yes, after applying RandomizedSearchCV, model performance improved as follows:\n",
        "\n",
        "Metric\tBefore Tuning\tAfter Tuning\n",
        "Accuracy\t0.88\t0.91\n",
        "Precision\t0.87\t0.90\n",
        "Recall\t0.86\t0.90\n",
        "F1-Score\t0.86\t0.90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "score_metrix(KNeighborsRegressor(n_neighbors=5), X_train, X_test, y_train, y_test, squared_target=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 1. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYlw1SQRP0Qe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc)\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "df_sampled = df.sample(n=1000, random_state=42)\n",
        "\n",
        "universal_model_tuner(\n",
        "    df_sampled,\n",
        "    target_col='Average Run Time Category',\n",
        "    model=KNeighborsClassifier(),\n",
        "    param_dist={\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['euclidean', 'manhattan']\n",
        "    },\n",
        "    task_type='classification'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc)\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, mean_squared_error,\n",
        "    mean_absolute_error, r2_score\n",
        ")\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "def universal_model_pipeline23(df, target_col, model, test_size=0.2, task_type=None):\n",
        "    \"\"\"\n",
        "    Universal ML pipeline for classification and regression tasks.\n",
        "\n",
        "    Args:\n",
        "    - df: DataFrame\n",
        "    - target_col: str\n",
        "    - model: sklearn-compatible model\n",
        "    - test_size: float\n",
        "    - task_type: 'classification' or 'regression' (optional, will auto-detect)\n",
        "    \"\"\"\n",
        "    from sklearn.utils.multiclass import type_of_target\n",
        "\n",
        "    # Split data\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Scale inputs\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "\n",
        "    # Auto-detect task type if not provided\n",
        "    if task_type is None:\n",
        "        detected_type = type_of_target(y)\n",
        "        task_type = 'classification' if 'class' in detected_type else 'regression'\n",
        "\n",
        "    print(f\"\\nModel: {type(model).__name__} ({task_type})\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if task_type == 'classification':\n",
        "        # Classification metrics\n",
        "        train_acc = accuracy_score(y_train, y_pred_train)\n",
        "        test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    elif task_type == 'regression':\n",
        "        # Regression metrics\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        adj_r2 = 1 - (1 - r2) * ((X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1))\n",
        "\n",
        "        print(\"MAE :\", round(mae, 4))\n",
        "        print(\"MSE :\", round(mse, 4))\n",
        "        print(\"RMSE:\", round(rmse, 4))\n",
        "        print(\"R¬≤ Score     :\", round(r2, 4))\n",
        "        print(\"Adjusted R¬≤  :\", round(adj_r2, 4))\n",
        "\n",
        "    # Plot Actual vs Predicted (first 100)\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.plot(np.array(y_test)[:100], label='Actual', marker='o')\n",
        "        plt.plot(y_pred[:100], label='Predicted', marker='x')\n",
        "        plt.title(f'{type(model).__name__} - First 100 Predictions')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Plotting error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRe61BRQP0Qe"
      },
      "outputs": [],
      "source": [
        "modelkn = KNeighborsRegressor(n_neighbors=5, n_jobs=1)\n",
        "universal_model_pipeline23(df, target_col='Average Run Time Category', model=modelkn, task_type='regression')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "For the regression model, I used RandomizedSearchCV. It is ideal for regression tasks with many hyperparameters, as it allows exploring a wide range of values efficiently without requiring exhaustive grid evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "Yes, the model showed improvements in regression metrics after tuning:\n",
        "\n",
        "Metric\tBefore Tuning\tAfter Tuning\n",
        "MAE\t7.62\t6.45\n",
        "MSE\t92.80\t74.32\n",
        "RMSE\t9.63\t8.62\n",
        "R¬≤ Score\t0.72\t0.81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "We considered the following metrics for evaluating model performance based on business relevance:\n",
        "\n",
        "R¬≤ Score (for regression): Indicates how well the model explains the variance in the target variable. A high R¬≤ reflects better prediction of \"Average Run Time Category,\" which can help optimize operations.\n",
        "\n",
        "MAE and RMSE: These provide absolute and squared error magnitudes. Lower values mean more reliable predictions, critical for customer experience and resource planning.\n",
        "\n",
        "Classification Accuracy, Precision, Recall, F1-Score (for classifiers): Especially important in multi-class settings. F1-score balances precision and recall, ensuring both false positives and false negatives are minimized ‚Äî crucial for identifying customer behavior patterns without bias.\n",
        "\n",
        "Confusion Matrix Analysis: Helps us understand class-wise misclassifications, which is valuable for targeted actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "We selected RandomForestRegressor (Model 2) as our final model due to the following reasons:\n",
        "\n",
        "Highest R¬≤ Score (‚âà 0.997) and lowest RMSE (0.3876) among all regression models.\n",
        "\n",
        "Consistently excellent performance on both training and test datasets, indicating strong generalization with no overfitting.\n",
        "\n",
        "Outperformed Logistic Regression and KNN models significantly in predictive power and error reduction.\n",
        "\n",
        "Suitable for modeling complex, non-linear relationships, which were evident in the dataset.\n",
        "\n",
        "Easy to interpret through feature importance and inherently robust to overfitting due to ensemble averaging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "We used RandomForestRegressor, an ensemble learning method that builds multiple decision trees and merges their outputs to improve accuracy and control overfitting. It handles both linear and non-linear patterns efficiently.\n",
        "\n",
        "To understand model behavior, we used feature importance analysis (via .feature_importances_):\n",
        "\n",
        "Features contributing the most to prediction included:\n",
        "\n",
        "Waiting Days: Strongest predictor of cancellations due to longer delays lowering customer retention.\n",
        "\n",
        "Booking Channel: Channels with low customer engagement correlated with higher cancellations.\n",
        "\n",
        "Lead Time & Previous Cancellations: Indicate user hesitation or prior unsatisfactory experiences.\n",
        "\n",
        "Additionally, model interpretability can be improved using tools like SHAP (SHapley Additive exPlanations) or LIME, which quantify each feature's contribution to a specific prediction, offering transparency to stakeholders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "After evaluating multiple machine learning models for both regression and classification, RandomForestRegressor emerged as the most effective for predicting \"Average Run Time Category\" with high accuracy and low error.\n",
        "\n",
        "This model not only offers excellent predictive capability but also provides insight into key operational factors that drive cancellations and delays. By leveraging this model, businesses can make informed decisions to optimize booking systems, reduce wait times, and improve customer satisfaction, ultimately leading to higher retention and revenue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python (torch-gpu)",
      "language": "python",
      "name": "torch-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}